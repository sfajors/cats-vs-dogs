{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# import os libraries\nimport os\nimport shutil\nimport itertools\nimport pathlib\nfrom PIL import Image\n\n# import data handling\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom sklearn.metrics import confusion_matrix , classification_report, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\n# import deep learning tools\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D , MaxPooling2D , Dense , BatchNormalization , Dropout,Flatten , Activation\nfrom tensorflow.keras.optimizers import Adam , Adamax\nfrom tensorflow.keras import regularizers\n\n# warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-04T23:22:17.630917Z","iopub.execute_input":"2023-10-04T23:22:17.632159Z","iopub.status.idle":"2023-10-04T23:22:28.050906Z","shell.execute_reply.started":"2023-10-04T23:22:17.632117Z","shell.execute_reply":"2023-10-04T23:22:28.049959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unzipping Data","metadata":{}},{"cell_type":"code","source":"# Unzips the train file \n!unzip /kaggle/input/dogs-vs-cats/train.zip","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:28.052743Z","iopub.execute_input":"2023-10-04T23:22:28.053633Z","iopub.status.idle":"2023-10-04T23:22:40.548870Z","shell.execute_reply.started":"2023-10-04T23:22:28.053599Z","shell.execute_reply":"2023-10-04T23:22:40.547763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unzips the test1 file\n!unzip /kaggle/input/dogs-vs-cats/test1.zip","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:40.550585Z","iopub.execute_input":"2023-10-04T23:22:40.550963Z","iopub.status.idle":"2023-10-04T23:22:46.858884Z","shell.execute_reply.started":"2023-10-04T23:22:40.550929Z","shell.execute_reply":"2023-10-04T23:22:46.857773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counts the number of files\npath , dirs , files = next(os.walk('/kaggle/working/train'))\nfile_count = len(files)\n\n# Should be 25000 files\nprint(file_count)\nbase_dir = '/kaggle/working/dogs_vs_cats_small'\nos.mkdir(base_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:46.861955Z","iopub.execute_input":"2023-10-04T23:22:46.862588Z","iopub.status.idle":"2023-10-04T23:22:46.891399Z","shell.execute_reply.started":"2023-10-04T23:22:46.862561Z","shell.execute_reply":"2023-10-04T23:22:46.890392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Organize the data\nCreates a directory structure for organizing files","metadata":{}},{"cell_type":"code","source":"# Make a new train directory inside my base directory\ntrain_dir = os.path.join(base_dir , 'train')\nos.mkdir(train_dir)\n\n# Make a new validation directory inside my base directory\nvalid_dir= os.path.join(base_dir , 'validation')\nos.mkdir(valid_dir)\n\n# Make a new test directory inside my base directory\ntest_dir = os.path.join(base_dir , 'test')\nos.mkdir(test_dir)\n\n# Make a new cats directory inside my train directory\ntrain_cats_dir = os.path.join(train_dir , 'cats')\nos.mkdir(train_cats_dir)\n\n# Make a new dogs directory inside my train directory\ntrain_dogs_dir = os.path.join(train_dir , 'dogs')\nos.mkdir(train_dogs_dir)\n\n# Make a new cats directory inside my validation directory\nvalid_cats_dir = os.path.join(valid_dir, 'cats')\nos.mkdir(valid_cats_dir)\n\n# Make a new dogs directory inside my validation directory\nvalid_dogs_dir = os.path.join(valid_dir , 'dogs')\nos.mkdir(valid_dogs_dir)\n\n# Make a new cats directory inside my test directory\ntest_cats_dir = os.path.join(test_dir , 'cats')\nos.mkdir(test_cats_dir)\n\n# Make a new dogs directory inside my test directory\ntest_dogs_dir = os.path.join(test_dir , 'dogs')\nos.mkdir(test_dogs_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:46.892784Z","iopub.execute_input":"2023-10-04T23:22:46.893363Z","iopub.status.idle":"2023-10-04T23:22:46.902163Z","shell.execute_reply.started":"2023-10-04T23:22:46.893314Z","shell.execute_reply":"2023-10-04T23:22:46.901204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counts the number of files in the directory working Kaggle directory \ndir_path = '/kaggle/working/train'\n\ncat_count = 0\ndog_count= 0\nfor i in os.listdir(dir_path):\n    if i.startswith('cat.'):\n        cat_count += 1\n    elif i.startswith('dog.'):\n        dog_count += 1","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:46.905101Z","iopub.execute_input":"2023-10-04T23:22:46.905932Z","iopub.status.idle":"2023-10-04T23:22:46.935876Z","shell.execute_reply.started":"2023-10-04T23:22:46.905898Z","shell.execute_reply":"2023-10-04T23:22:46.935108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the dataset\nThis snippet is responsible for splitting the dataset images into training, validation, and test sets by copying specific files into their respective directories","metadata":{}},{"cell_type":"code","source":"original_dataset_dir = '/kaggle/working/train'\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(10001)] #Move 10,000 cat images from the original dataset to the train cat directory\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir , fname)\n  dst = os.path.join(train_cats_dir , fname)\n  shutil.copyfile(src , dst)\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(10001,11251)] #Move 1250 cat images from the original dataset to the validation cat directory\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir , fname)\n  dst = os.path.join(valid_cats_dir , fname)\n  shutil.copyfile(src,dst)\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(11251,12500)] #Move 1250 cat images from the original dataset to the test cat directory\nfor fname in fnames:\n  src= os.path.join(original_dataset_dir , fname)\n  dst= os.path.join(test_cats_dir, fname)\n  shutil.copyfile(src,dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(10001)] #Move 10,000 dog images from the original dataset to the train cat directory\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir , fname)\n  dst = os.path.join(train_dogs_dir ,fname)\n  shutil.copyfile(src,dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(10001,11251)] #Move 1250 dog images from the original dataset to the validation cat directory\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir,fname)\n  dst = os.path.join(valid_dogs_dir , fname)\n  shutil.copyfile(src,dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(11251,12500)]#Move 1250 dog images from the original dataset to the test cat directory\nfor fname in fnames:\n  src= os.path.join(original_dataset_dir, fname)\n  dst = os.path.join(test_dogs_dir , fname)\n  shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:46.937088Z","iopub.execute_input":"2023-10-04T23:22:46.937650Z","iopub.status.idle":"2023-10-04T23:22:49.863307Z","shell.execute_reply.started":"2023-10-04T23:22:46.937616Z","shell.execute_reply":"2023-10-04T23:22:49.862389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data augmentation\n","metadata":{}},{"cell_type":"code","source":"img_size = (224 , 224)\nbatch_size = 32\nimg_shape = (img_size[0] , img_size[1] , 3)\n\ntr_gen = ImageDataGenerator()\nts_gen = ImageDataGenerator()\n\ntrain_gen = tr_gen.flow_from_directory(train_dir , target_size = img_size , class_mode = 'binary' , \n                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n\nvalid_gen = ts_gen.flow_from_directory(valid_dir , target_size = img_size , class_mode = 'binary' , \n                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n\ntest_gen = ts_gen.flow_from_directory(test_dir , target_size = img_size , class_mode = 'binary' , \n                                       color_mode = 'rgb' , shuffle = False , batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:49.864693Z","iopub.execute_input":"2023-10-04T23:22:49.865407Z","iopub.status.idle":"2023-10-04T23:22:50.295239Z","shell.execute_reply.started":"2023-10-04T23:22:49.865365Z","shell.execute_reply":"2023-10-04T23:22:50.294465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize a sample of images from the dataset","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices\nclasses = list(g_dict.keys())\nimages, labels = next(train_gen)\nnum_samples = len(images)\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(min(16, num_samples)):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255\n    plt.imshow(image)\n    class_index = int(labels[i])\n    class_name = classes[class_index]\n    plt.title(class_name, color='blue', fontsize=12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:50.297312Z","iopub.execute_input":"2023-10-04T23:22:50.297955Z","iopub.status.idle":"2023-10-04T23:22:53.915016Z","shell.execute_reply.started":"2023-10-04T23:22:50.297923Z","shell.execute_reply":"2023-10-04T23:22:53.913798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNetB5 Architecture","metadata":{}},{"cell_type":"code","source":"img_shape = (img_size[0] , img_size[1] , 3)\nbase_model = tf.keras.applications.efficientnet.EfficientNetB5(include_top= False , weights= 'imagenet' ,\n                                                               input_shape= img_shape,pooling= 'max')\nbase_model.trainable= False\n\nnum_classes = len(classes)\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis = -1 , momentum = 0.99 , epsilon = 0.001),\n    Dense(256, kernel_regularizer = regularizers.l2(l= 0.016) , activity_regularizer = regularizers.l1(0.006),\n         bias_regularizer= regularizers.l1(0.006) , activation = 'relu'),\n    Dropout(rate = 0.4 , seed = 40),\n    Dense(1 , activation= 'sigmoid' )\n])\nmodel.compile(Adamax(learning_rate = 0.001) , loss = 'binary_crossentropy' , metrics= ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:22:53.919148Z","iopub.execute_input":"2023-10-04T23:22:53.919527Z","iopub.status.idle":"2023-10-04T23:23:07.652043Z","shell.execute_reply.started":"2023-10-04T23:22:53.919495Z","shell.execute_reply":"2023-10-04T23:23:07.651051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"history = model.fit(x= train_gen , validation_data= valid_gen , epochs= 10 , verbose = 1 , validation_steps = None , shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:23:07.653495Z","iopub.execute_input":"2023-10-04T23:23:07.654532Z","iopub.status.idle":"2023-10-04T23:55:04.941527Z","shell.execute_reply.started":"2023-10-04T23:23:07.654495Z","shell.execute_reply":"2023-10-04T23:55:04.940554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model","metadata":{}},{"cell_type":"code","source":"train_score = model.evaluate(train_gen , steps= 32 , verbose = 1)\nval_score = model.evaluate(valid_gen , steps = 32 , verbose = 1)\ntest_score = model.evaluate(test_gen , steps = 32 , verbose = 1)\n\nprint(f'Train loss = {train_score[0] }')\nprint(f'Train Accuracy = {train_score[1]}')\nprint(f'Validation loss = {val_score[0]}')\nprint(f'Validation Accuracy = {val_score[1]}')\nprint(f'Test loss = {test_score[0]}')\nprint(f'Test Accuracy = {test_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:57:10.015169Z","iopub.execute_input":"2023-10-04T23:57:10.015543Z","iopub.status.idle":"2023-10-04T23:57:33.063548Z","shell.execute_reply.started":"2023-10-04T23:57:10.015511Z","shell.execute_reply":"2023-10-04T23:57:33.062506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample outline for prediction","metadata":{}},{"cell_type":"code","source":"def predict_image_using_model(model, image_path, img_size=(224, 224)):\n    # Preprocess the image\n    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n    img = cv2.resize(img, img_size)\n    img = np.array(img)\n    img = np.expand_dims(img, axis=0)  # Expand dimensions to match the model's input shape\n    \n    # Make a prediction\n    predictions = model.predict(img)\n    predicted_class = int(predictions > 0.5)  # Convert probability to class label (0 or 1)\n    \n    # Interpret the prediction\n    if predicted_class == 0:\n        label = \"cat\"\n    else:\n        label = \"dog\"\n    \n    confidence = predictions[0][0] * 100 if label == \"dog\" else (1 - predictions[0][0]) * 100\n    print(f\"The image is predicted to be a {label} with {confidence:.2f}% confidence.\")\n\n# Usage example\nimage_path = \"/kaggle/input/cat-image/download.jpg\"\npredict_image_using_model(model, image_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T23:57:38.964164Z","iopub.execute_input":"2023-10-04T23:57:38.964858Z","iopub.status.idle":"2023-10-04T23:57:43.396797Z","shell.execute_reply.started":"2023-10-04T23:57:38.964825Z","shell.execute_reply":"2023-10-04T23:57:43.395588Z"},"trusted":true},"execution_count":null,"outputs":[]}]}